{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoro1092000/ZOZO/blob/master/Test_my_model_elu_batchsize_4_005_095.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mv4nJ2jKe6D",
        "outputId": "4916a61e-5ee2-40e7-fa9a-b08c4a00f1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 20 00:44:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KD-KUsKDiLE"
      },
      "source": [
        "# I. Pip & Import."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7D6x31EU0fi",
        "outputId": "5ba51699-aa76-49af-804c-405ab89486f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric==1.4.3 in /usr/local/lib/python3.7/dist-packages (1.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (1.7.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (0.18.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (1.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (1.12.1+cu113)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (0.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (0.56.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (1.3.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (6.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (1.21.6)\n",
            "Requirement already satisfied: plyfile in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.3) (0.7.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric==1.4.3) (1.5.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.4.3) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.4.3) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.4.3) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->torch-geometric==1.4.3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->torch-geometric==1.4.3) (3.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.4.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.4.3) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric==1.4.3) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.4.3) (0.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.4.3) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.3) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.3) (2.10)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.3) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.3) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.3) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.3) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.3) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.3) (0.11.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.4.3) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.4.3) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deepdish==0.3.5 in /usr/local/lib/python3.7/dist-packages (0.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (1.21.6)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (3.7.0)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables->deepdish==0.3.5) (2.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tables->deepdish==0.3.5) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tables->deepdish==0.3.5) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric==1.4.3\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install deepdish==0.3.5\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.utils import scatter_\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_scatter import scatter_add\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ELU, Dropout\n",
        "from torch_geometric.nn import GINConv\n",
        "\n",
        "from itertools import chain\n",
        "import pickle\n",
        "import h5py\n",
        "import deepdish as dd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import inspect\n",
        "import time\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X5j9SrCo4uM5"
      },
      "outputs": [],
      "source": [
        "def time_since(start):\n",
        "    now = time.time()\n",
        "    s = now - start\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    h = math.floor(m / 60)\n",
        "    m -= h * 60\n",
        "    if h == 0:\n",
        "        if m == 0:\n",
        "            return '%ds' % s\n",
        "        else:\n",
        "            return '%dm %ds' % (m, s)\n",
        "    else:\n",
        "        return '%dh %dm %ds' % (h, m, s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0VJxZnIDpJT"
      },
      "source": [
        "# II. Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JHHcJ7B-4BmU"
      },
      "outputs": [],
      "source": [
        "# Data utils\n",
        "def h5group_to_dict(h5group):\n",
        "    group_dict = {k: v[()] for k, v in chain(h5group.items(), h5group.attrs.items())}\n",
        "    return group_dict\n",
        "\n",
        "def sub_dict(full_dict, *keys, to_tensor):\n",
        "    return {k: torch.tensor(full_dict[k]) if to_tensor else full_dict[k] for k in keys if k in full_dict}\n",
        "\n",
        "def build_graph_from_dict_pyg(graph_dict, to_tensor=True):\n",
        "    from torch_geometric.data import Data\n",
        "\n",
        "    g = Data(**sub_dict(graph_dict, 'edge_index', 'x', 'y', 'edge_attr', 'edge_y', to_tensor=to_tensor))\n",
        "    return g\n",
        "\n",
        "# Data loader\n",
        "class GraphDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, batch_size=128, shuffle=False, num_workers=0):\n",
        "\n",
        "        def collate_graph(graph_obj_list):\n",
        "            from torch_geometric.data import Batch\n",
        "            batch = Batch.from_data_list(graph_obj_list)\n",
        "            return batch\n",
        "\n",
        "        super().__init__(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            collate_fn=collate_graph,\n",
        "            num_workers=num_workers)\n",
        "\n",
        "# BotnetDataset\n",
        "class BotnetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, name='chord', root='data/botnet', split='train', graph_format='pyg', split_idx=None, add_nfeat_ones=True,\n",
        "                 in_memory=True):\n",
        "        super().__init__()\n",
        "        assert name in ['chord', 'debru', 'kadem', 'leet', 'c2', 'p2p']\n",
        "        assert split in ['train', 'val', 'test']\n",
        "\n",
        "        if isinstance(root, str):\n",
        "            root = osp.expanduser(osp.normpath(root))\n",
        "\n",
        "        self.name = name\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.split_idx = split_idx\n",
        "        self.add_nfeat_ones = add_nfeat_ones\n",
        "\n",
        "        self._graph_format = graph_format\n",
        "        if split == 'train':\n",
        "            self.path = self.processed_paths[0]\n",
        "        elif split == 'val':\n",
        "            self.path = self.processed_paths[1]\n",
        "        elif split == 'test':\n",
        "            self.path = self.processed_paths[2]\n",
        "\n",
        "        # in_memory = False\n",
        "        # self.data = h5py.File(self.path, 'r')\n",
        "        self.data = None    # defer opening file in each process to make multiprocessing work\n",
        "        self.data_type = 'file'\n",
        "        with h5py.File(self.path, 'r') as f:\n",
        "            self.num_graphs = f.attrs['num_graphs']\n",
        "            \n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "        return osp.join(self.root, 'processed')\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.name + '_' + s + '.hdf5' for s in ('train', 'val', 'test')]\n",
        "\n",
        "    @property\n",
        "    def processed_paths(self):\n",
        "        return [osp.join(self.processed_dir, f) for f in self.processed_file_names]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_graphs\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.data_type == 'dict':\n",
        "            graph_dict = self.data[str(index)]\n",
        "        elif self.data_type == 'file':\n",
        "            if self.data is None:\n",
        "                # only open once in each process\n",
        "                self.data = h5py.File(self.path, 'r')\n",
        "            graph_dict = h5group_to_dict(self.data[str(index)])\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "        # graph_format == 'pyg':\n",
        "        return build_graph_from_dict_pyg(graph_dict)\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(self.num_graphs):\n",
        "            yield self[i]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(topology: {self.name} | split: {self.split} | ' \\\n",
        "               f'#graphs: {len(self)} | graph format: {self.graph_format})'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igYJ4y99D-bU"
      },
      "source": [
        "# III. Measure Performancce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_dcpDhREijU"
      },
      "source": [
        "## 3.1. Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BN-QIjMREw-7"
      },
      "outputs": [],
      "source": [
        "def f1(target, pred, label):\n",
        "    # F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    tp = np.sum((target==label) & (pred==label))\n",
        "    fp = np.sum((target!=label) & (pred==label))\n",
        "    fn = np.sum((pred!=label) & (target==label))\n",
        "    \n",
        "    if tp+fp==0 or tp+fn==0:\n",
        "      return np.nan\n",
        "\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    \n",
        "    if precision+recall==0:\n",
        "      return np.nan\n",
        "      \n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def f1_macro(pred, target):\n",
        "    return np.mean([f1(target, pred, label) for label in range(0, 2)])\n",
        "\n",
        "\n",
        "def accuracy(pred, target):\n",
        "    return (pred == target).sum().item() / len(target)\n",
        "\n",
        "\n",
        "def true_positive(pred, target):\n",
        "    return (target[pred == 1] == 1).sum().item()\n",
        "\n",
        "\n",
        "def false_positive(pred, target):\n",
        "    return (target[pred == 1] == 0).sum().item()\n",
        "\n",
        "\n",
        "def true_negative(pred, target):\n",
        "    return (target[pred == 0] == 0).sum().item()\n",
        "\n",
        "\n",
        "def false_negative(pred, target):\n",
        "    return (target[pred == 0] == 1).sum().item()\n",
        "\n",
        "\n",
        "def recall(pred, target):\n",
        "    try:\n",
        "        return true_positive(pred, target) / (target == 1).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def precision(pred, target):\n",
        "    try:\n",
        "        prec = true_positive(pred, target) / (pred == 1).sum().item()\n",
        "        return prec\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def f1_score(pred, target):\n",
        "    prec = precision(pred, target)\n",
        "    rec = recall(pred, target)\n",
        "    try:\n",
        "        return 2 * (prec * rec) / (prec + rec)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def false_positive_rate(pred, target):\n",
        "    try:\n",
        "        return false_positive(pred, target) / (target == 0).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def false_negative_rate(pred, target):\n",
        "    try:\n",
        "        return false_negative(pred, target) / (target == 1).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTEnWpOOEZW9"
      },
      "source": [
        "## 3.2. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pqjalkx1EmHc"
      },
      "outputs": [],
      "source": [
        "def eval_metrics(target, pred_prob, threshold=0.5):\n",
        "    if isinstance(target, torch.Tensor):\n",
        "        target = target.cpu().numpy()\n",
        "    if isinstance(pred_prob, torch.Tensor):\n",
        "        pred_prob = pred_prob.cpu().numpy()\n",
        "\n",
        "    pred = (pred_prob >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy(pred, target)\n",
        "    fpr = false_positive_rate(pred, target)\n",
        "    fnr = false_negative_rate(pred, target)\n",
        "    rec = recall(pred, target)\n",
        "    prc = precision(pred, target)\n",
        "    f1 = f1_score(pred, target)\n",
        "    f1macro = f1_macro(pred, target)\n",
        "    result_dict = {'acc': acc, 'fpr': fpr, 'fnr': fnr, 'rec': rec, 'prc': prc, 'f1': f1, 'f1_macro': f1macro}\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "\n",
        "def dict_value_add(dict1, dict2):\n",
        "    result = {key: dict1.get(key, 0) + dict2.get(key, 0)\n",
        "              for key in set(dict1) | set(dict2)}\n",
        "    return result\n",
        "\n",
        "\n",
        "def dict_value_div(dict, n):\n",
        "    result = {key: value / n for key, value in dict.items()}\n",
        "    return result\n",
        "\n",
        "\n",
        "def eval_predictor(dataset, predictor):\n",
        "    result_dict_avg = {}\n",
        "    loss_avg = 0\n",
        "\n",
        "    for data in dataset:\n",
        "        # prediction\n",
        "        try:\n",
        "            pred_prob, loss = predictor(data)\n",
        "            loss_avg += loss\n",
        "        except ValueError:  # if \"too many values to unpack\"\n",
        "            pred_prob = predictor(data)\n",
        "\n",
        "        # get the ground truth target\n",
        "        # graph_format == 'pyg':\n",
        "        target = data.y\n",
        "\n",
        "        # compute the evaluation metrics\n",
        "        result_dict = eval_metrics(target, pred_prob)\n",
        "\n",
        "        result_dict_avg = dict_value_add(result_dict_avg, result_dict)\n",
        "\n",
        "    # average the metrics across all graphs in the dataset as final results\n",
        "    result_dict_avg = dict_value_div(result_dict_avg, len(dataset))\n",
        "    loss_avg = loss_avg / len(dataset)\n",
        "\n",
        "    return result_dict_avg, loss_avg\n",
        "\n",
        "\n",
        "# =================================================================================================================\n",
        "# some examples of the 'predictor' model wrapper to be fed into the above evaluation function (for PyG Data format)\n",
        "# =================================================================================================================\n",
        "class PygRandomPredictor:\n",
        "    def __init__(self):\n",
        "        # torch.manual_seed(0)\n",
        "        pass\n",
        "\n",
        "    def __call__(self, data):\n",
        "        pred_prob = torch.rand(len(data.y))\n",
        "        return pred_prob\n",
        "\n",
        "\n",
        "class PygModelPredictor:\n",
        "    def __init__(self, model, loss_fcn=torch.nn.CrossEntropyLoss()):\n",
        "        self.model = model\n",
        "        self.loss_fcn = loss_fcn\n",
        "        self.device = next(model.parameters()).device\n",
        "\n",
        "    def __call__(self, data):\n",
        "        self.model.eval()\n",
        "        data = data.to(self.device)\n",
        "        with torch.no_grad():\n",
        "            # custom the below line to adjust to your model's input format for forward pass\n",
        "            out = self.model(data.x, data.edge_index)\n",
        "            loss = self.loss_fcn(out, data.y.long())\n",
        "            pred_prob = torch.softmax(out, dim=1)[:, 1]\n",
        "        return pred_prob, loss.float()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fvRugR_E1QL"
      },
      "source": [
        "# IV. GIN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vLv8xNFcFqcT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GINModel(nn.Module):\n",
        "    def __init__(self, dim_input_feature, dim_hidden_feature, num_layers, num_classes, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dim_input_feature = dim_input_feature\n",
        "        self.dim_hidden_feature = dim_hidden_feature\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "        self.non_linear = nn.ELU()\n",
        "\n",
        "        self.gin_net = nn.ModuleList()\n",
        "        for i in range(self.num_layers):\n",
        "          if i == 0:\n",
        "            self.gin_net.append(\n",
        "                GINConv(\n",
        "                  Sequential(Linear(self.dim_input_feature, self.dim_hidden_feature),\n",
        "                             BatchNorm1d(self.dim_hidden_feature), ELU(),\n",
        "                             Linear(self.dim_hidden_feature, self.dim_hidden_feature), ELU()), train_eps = True))\n",
        "          else:\n",
        "            self.gin_net.append(\n",
        "                GINConv(\n",
        "                  Sequential(Linear(self.dim_hidden_feature, self.dim_hidden_feature),\n",
        "                             BatchNorm1d(self.dim_hidden_feature), ELU(),\n",
        "                             Linear(self.dim_hidden_feature, self.dim_hidden_feature), ELU()), train_eps = True)) \n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.residuals = nn.ModuleList()\n",
        "        for i in range(self.num_layers):\n",
        "          if i == 0:\n",
        "            self.residuals.append(nn.Linear(self.dim_input_feature, self.dim_hidden_feature, bias=True))\n",
        "          else:\n",
        "            self.residuals.append(nn.Identity())\n",
        "\n",
        "        self.num_residuals = len(self.residuals)\n",
        "\n",
        "        # self.final_type == 'proj':\n",
        "        self.final = nn.Linear(self.dim_hidden_feature, num_classes)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for net in self.gin_net:\n",
        "            net.reset_parameters()\n",
        "        # self.residual_hop = 1\n",
        "        for net in self.residuals:\n",
        "            net.reset_parameters()\n",
        "        # self.final_type != 'none':\n",
        "        self.final.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        xr = None\n",
        "        add_xr_at = -1\n",
        "\n",
        "        for n, net in enumerate(self.gin_net):\n",
        "            # pass to a GIN layer with non-linear activation\n",
        "            xo = net(x, edge_index)\n",
        "            xo = self.dropout(xo)\n",
        "            # deal with residual connections\n",
        "            # self.residual_hop = 1\n",
        "            if n < self.num_residuals:\n",
        "                xr = self.residuals[n](x)\n",
        "                add_xr_at = n\n",
        "            if n == add_xr_at:\n",
        "                xo = self.non_linear(xo + xr)\n",
        "\n",
        "            x = xo\n",
        "        # size of x: (B * N, dim_hidden_feature) -> (B * N, num_classes)\n",
        "        x = self.final(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRCYp7yuLxMe"
      },
      "source": [
        "# V. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msBAy6CKLwl8",
        "outputId": "d718479f-c6b5-40f3-99fe-55b98586cc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dataset...\n",
            "p2p\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/Shareddrives/botnetdata/P2P'\n",
        "data_name = 'p2p' # 'chord', 'debru', 'kadem', 'leet', 'c2', 'p2p'\n",
        "batch_size = 4\n",
        "in_memory = False\n",
        "shuffle = False\n",
        "\n",
        "# ========== load the dataset\n",
        "print('loading dataset...')\n",
        "\n",
        "train_ds = BotnetDataset(name=data_name, root=data_dir, split='train',\n",
        "                         in_memory=bool(in_memory), graph_format='pyg')\n",
        "val_ds = BotnetDataset(name=data_name, root=data_dir, split='val',\n",
        "                       in_memory=bool(in_memory), graph_format='pyg')\n",
        "test_ds = BotnetDataset(name=data_name, root=data_dir, split='test',\n",
        "                        in_memory=bool(in_memory), graph_format='pyg')\n",
        "train_loader = GraphDataLoader(train_ds, batch_size=batch_size, shuffle=bool(shuffle), num_workers=0)\n",
        "print(data_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSY11P9WEX5a"
      },
      "source": [
        "# VI. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3iFDupzCdBl0",
        "outputId": "dd77a03a-d74b-4936-c64a-cd40e7856351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-3b50c76d-a73d-41e9-ab06-8bc9dd49d641.json\n",
            "------------------------------\n",
            "------------------------------\n",
            "Thu Oct 20 00:44:39 2022\n",
            "------------------------------\n",
            "model ----------\n",
            "GINModel(\n",
            "  (non_linear): ELU(alpha=1.0)\n",
            "  (gin_net): ModuleList(\n",
            "    (0): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=1, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (1): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (2): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (3): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (4): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (5): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (6): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (7): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (8): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (9): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (10): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "    (11): GINConv(nn=Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ELU(alpha=1.0)\n",
            "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (4): ELU(alpha=1.0)\n",
            "    ))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (residuals): ModuleList(\n",
            "    (0): Linear(in_features=1, out_features=32, bias=True)\n",
            "    (1): Identity()\n",
            "    (2): Identity()\n",
            "    (3): Identity()\n",
            "    (4): Identity()\n",
            "    (5): Identity()\n",
            "    (6): Identity()\n",
            "    (7): Identity()\n",
            "    (8): Identity()\n",
            "    (9): Identity()\n",
            "    (10): Identity()\n",
            "    (11): Identity()\n",
            "  )\n",
            "  (final): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n",
            "epoch: 1, passed number of graphs: 96, train running loss: 0.13455 (passed time: 1m 26s)\n",
            "          acc: 0.88825, fpr: 0.11109, fnr: 0.14173, rec: 0.85827, prc: 0.14549, f1: 0.24880, f1_macro: 0.59422\n",
            "epoch: 1, passed number of graphs: 192, train running loss: 0.08543 (passed time: 1m 54s)\n",
            "          acc: 0.97946, fpr: 0.01823, fnr: 0.12666, rec: 0.87334, prc: 0.51044, f1: 0.64430, f1_macro: 0.81686\n",
            "epoch: 1, passed number of graphs: 288, train running loss: 0.06460 (passed time: 2m 22s)\n",
            "          acc: 0.98819, fpr: 0.01192, fnr: 0.00677, rec: 0.99323, prc: 0.64562, f1: 0.78256, f1_macro: 0.88824\n",
            "epoch: 1, passed number of graphs: 384, train running loss: 0.05059 (passed time: 2m 50s)\n",
            "          acc: 0.99630, fpr: 0.00376, fnr: 0.00097, rec: 0.99903, prc: 0.85443, f1: 0.92109, f1_macro: 0.95960\n",
            "epoch: 1, passed number of graphs: 480, train running loss: 0.04164 (passed time: 3m 15s)\n",
            "          acc: 0.99711, fpr: 0.00289, fnr: 0.00303, rec: 0.99697, prc: 0.88381, f1: 0.93698, f1_macro: 0.96775\n",
            "epoch: 1, passed number of graphs: 576, train running loss: 0.03596 (passed time: 3m 46s)\n",
            "          acc: 0.99902, fpr: 0.00082, fnr: 0.00811, rec: 0.99189, prc: 0.96380, f1: 0.97764, f1_macro: 0.98857\n",
            "epoch: 1, passed number of graphs: 672, train running loss: 0.03208 (passed time: 4m 13s)\n",
            "          acc: 0.99756, fpr: 0.00109, fnr: 0.06411, rec: 0.93589, prc: 0.94961, f1: 0.94270, f1_macro: 0.97072\n",
            "epoch: 1, passed number of graphs: 768, train running loss: 0.02902 (passed time: 4m 39s)\n",
            "          acc: 0.99947, fpr: 0.00048, fnr: 0.00261, rec: 0.99739, prc: 0.97820, f1: 0.98771, f1_macro: 0.99372\n",
            "Validation --- epoch: 1, loss: 0.12395\n",
            "          prc: 0.02222, fnr: 0.99354, acc: 0.97250, f1_macro: 0.49803, rec: 0.00646, fpr: 0.00626, f1: 0.01000\n",
            "Better model saved at ./saved_models/temp.pt.\n",
            "epoch: 2, passed number of graphs: 96, train running loss: 0.01012 (passed time: 5m 42s)\n",
            "          acc: 0.98403, fpr: 0.01626, fnr: 0.00305, rec: 0.99695, prc: 0.57471, f1: 0.72911, f1_macro: 0.86044\n",
            "epoch: 2, passed number of graphs: 192, train running loss: 0.01138 (passed time: 6m 9s)\n",
            "          acc: 0.99507, fpr: 0.00271, fnr: 0.10656, rec: 0.89344, prc: 0.87752, f1: 0.88540, f1_macro: 0.94144\n",
            "epoch: 2, passed number of graphs: 288, train running loss: 0.01016 (passed time: 6m 36s)\n",
            "          acc: 0.99619, fpr: 0.00388, fnr: 0.00049, rec: 0.99951, prc: 0.84924, f1: 0.91827, f1_macro: 0.95816\n",
            "epoch: 2, passed number of graphs: 384, train running loss: 0.00968 (passed time: 7m 4s)\n",
            "          acc: 0.99672, fpr: 0.00321, fnr: 0.00662, rec: 0.99338, prc: 0.87268, f1: 0.92913, f1_macro: 0.96372\n",
            "epoch: 2, passed number of graphs: 480, train running loss: 0.00862 (passed time: 7m 32s)\n",
            "          acc: 0.99935, fpr: 0.00065, fnr: 0.00049, rec: 0.99951, prc: 0.97123, f1: 0.98517, f1_macro: 0.99242\n",
            "epoch: 2, passed number of graphs: 576, train running loss: 0.00809 (passed time: 7m 59s)\n",
            "          acc: 0.99915, fpr: 0.00087, fnr: 0.00000, rec: 1.00000, prc: 0.96229, f1: 0.98078, f1_macro: 0.99018\n",
            "epoch: 2, passed number of graphs: 672, train running loss: 0.00773 (passed time: 8m 27s)\n",
            "          acc: 0.99783, fpr: 0.00102, fnr: 0.05464, rec: 0.94536, prc: 0.95324, f1: 0.94928, f1_macro: 0.97409\n",
            "epoch: 2, passed number of graphs: 768, train running loss: 0.00782 (passed time: 8m 54s)\n",
            "          acc: 0.99677, fpr: 0.00324, fnr: 0.00269, rec: 0.99731, prc: 0.86966, f1: 0.92912, f1_macro: 0.96373\n",
            "Validation --- epoch: 2, loss: 0.02328\n",
            "          prc: 0.78586, fnr: 0.01342, acc: 0.99358, f1_macro: 0.93426, rec: 0.98658, fpr: 0.00627, f1: 0.87180\n",
            "Better model saved at ./saved_models/temp.pt.\n",
            "epoch: 3, passed number of graphs: 96, train running loss: 0.00742 (passed time: 9m 44s)\n",
            "          acc: 0.99910, fpr: 0.00090, fnr: 0.00080, rec: 0.99920, prc: 0.96083, f1: 0.97964, f1_macro: 0.98959\n",
            "epoch: 3, passed number of graphs: 192, train running loss: 0.00797 (passed time: 10m 10s)\n",
            "          acc: 0.99695, fpr: 0.00096, fnr: 0.09892, rec: 0.90108, prc: 0.95335, f1: 0.92648, f1_macro: 0.96246\n",
            "epoch: 3, passed number of graphs: 288, train running loss: 0.00713 (passed time: 10m 37s)\n",
            "          acc: 0.99574, fpr: 0.00436, fnr: 0.00000, rec: 1.00000, prc: 0.83389, f1: 0.90942, f1_macro: 0.95362\n",
            "epoch: 3, passed number of graphs: 384, train running loss: 0.00688 (passed time: 11m 4s)\n",
            "          acc: 0.99741, fpr: 0.00263, fnr: 0.00081, rec: 0.99919, prc: 0.89371, f1: 0.94351, f1_macro: 0.97109\n",
            "epoch: 3, passed number of graphs: 480, train running loss: 0.00617 (passed time: 11m 31s)\n",
            "          acc: 0.99964, fpr: 0.00036, fnr: 0.00033, rec: 0.99967, prc: 0.98393, f1: 0.99174, f1_macro: 0.99578\n",
            "epoch: 3, passed number of graphs: 576, train running loss: 0.00619 (passed time: 11m 57s)\n",
            "          acc: 0.99896, fpr: 0.00100, fnr: 0.00281, rec: 0.99719, prc: 0.95656, f1: 0.97645, f1_macro: 0.98796\n",
            "epoch: 3, passed number of graphs: 672, train running loss: 0.01080 (passed time: 12m 24s)\n",
            "          acc: 0.98028, fpr: 0.01865, fnr: 0.06844, rec: 0.93156, prc: 0.52288, f1: 0.66980, f1_macro: 0.82982\n",
            "epoch: 3, passed number of graphs: 768, train running loss: 0.01128 (passed time: 12m 51s)\n",
            "          acc: 0.99694, fpr: 0.00289, fnr: 0.01083, rec: 0.98917, prc: 0.88120, f1: 0.93207, f1_macro: 0.96525\n",
            "Validation --- epoch: 3, loss: 0.03062\n",
            "          prc: 0.75841, fnr: 0.04000, acc: 0.99130, f1_macro: 0.91647, rec: 0.96000, fpr: 0.00801, f1: 0.83741\n",
            "epoch: 4, passed number of graphs: 96, train running loss: 0.00967 (passed time: 13m 42s)\n",
            "          acc: 0.99794, fpr: 0.00201, fnr: 0.00410, rec: 0.99590, prc: 0.91604, f1: 0.95431, f1_macro: 0.97663\n",
            "epoch: 4, passed number of graphs: 192, train running loss: 0.01117 (passed time: 14m 9s)\n",
            "          acc: 0.99455, fpr: 0.00341, fnr: 0.09957, rec: 0.90043, prc: 0.85192, f1: 0.87550, f1_macro: 0.93636\n",
            "epoch: 4, passed number of graphs: 288, train running loss: 0.01029 (passed time: 14m 36s)\n",
            "          acc: 0.99283, fpr: 0.00732, fnr: 0.00024, rec: 0.99976, prc: 0.74907, f1: 0.85644, f1_macro: 0.92638\n",
            "epoch: 4, passed number of graphs: 384, train running loss: 0.00931 (passed time: 15m 28s)\n",
            "          acc: 0.99722, fpr: 0.00283, fnr: 0.00040, rec: 0.99960, prc: 0.88658, f1: 0.93970, f1_macro: 0.96914\n",
            "epoch: 4, passed number of graphs: 480, train running loss: 0.00813 (passed time: 16m 28s)\n",
            "          acc: 0.99947, fpr: 0.00052, fnr: 0.00098, rec: 0.99902, prc: 0.97674, f1: 0.98775, f1_macro: 0.99374\n",
            "epoch: 4, passed number of graphs: 576, train running loss: 0.00776 (passed time: 17m 28s)\n",
            "          acc: 0.99943, fpr: 0.00048, fnr: 0.00490, rec: 0.99510, prc: 0.97868, f1: 0.98682, f1_macro: 0.99326\n",
            "epoch: 4, passed number of graphs: 672, train running loss: 0.00798 (passed time: 18m 28s)\n",
            "          acc: 0.99409, fpr: 0.00460, fnr: 0.06571, rec: 0.93429, prc: 0.81672, f1: 0.87156, f1_macro: 0.93427\n",
            "epoch: 4, passed number of graphs: 768, train running loss: 0.00794 (passed time: 19m 29s)\n",
            "          acc: 0.99790, fpr: 0.00213, fnr: 0.00057, rec: 0.99943, prc: 0.91048, f1: 0.95288, f1_macro: 0.97591\n",
            "Validation --- epoch: 4, loss: 0.01466\n",
            "          prc: 0.90524, fnr: 0.01332, acc: 0.99734, f1_macro: 0.97046, rec: 0.98668, fpr: 0.00243, f1: 0.94229\n",
            "Better model saved at ./saved_models/temp.pt.\n",
            "epoch: 5, passed number of graphs: 96, train running loss: 0.00565 (passed time: 21m 30s)\n",
            "          acc: 0.99989, fpr: 0.00010, fnr: 0.00056, rec: 0.99944, prc: 0.99536, f1: 0.99739, f1_macro: 0.99867\n",
            "epoch: 5, passed number of graphs: 192, train running loss: 0.00654 (passed time: 22m 30s)\n",
            "          acc: 0.99671, fpr: 0.00121, fnr: 0.09884, rec: 0.90116, prc: 0.94193, f1: 0.92109, f1_macro: 0.95971\n",
            "epoch: 5, passed number of graphs: 288, train running loss: 0.00585 (passed time: 23m 30s)\n",
            "          acc: 0.99671, fpr: 0.00336, fnr: 0.00008, rec: 0.99992, prc: 0.86663, f1: 0.92851, f1_macro: 0.96341\n",
            "epoch: 5, passed number of graphs: 384, train running loss: 0.00523 (passed time: 24m 30s)\n",
            "          acc: 0.99991, fpr: 0.00005, fnr: 0.00178, rec: 0.99822, prc: 0.99774, f1: 0.99798, f1_macro: 0.99897\n",
            "epoch: 5, passed number of graphs: 480, train running loss: 0.00463 (passed time: 25m 30s)\n",
            "          acc: 0.99951, fpr: 0.00050, fnr: 0.00008, rec: 0.99992, prc: 0.97794, f1: 0.98881, f1_macro: 0.99428\n",
            "epoch: 5, passed number of graphs: 576, train running loss: 0.00433 (passed time: 26m 30s)\n",
            "          acc: 0.99986, fpr: 0.00010, fnr: 0.00177, rec: 0.99823, prc: 0.99536, f1: 0.99679, f1_macro: 0.99836\n",
            "epoch: 5, passed number of graphs: 672, train running loss: 0.00473 (passed time: 27m 30s)\n",
            "          acc: 0.99839, fpr: 0.00134, fnr: 0.01404, rec: 0.98596, prc: 0.94168, f1: 0.96331, f1_macro: 0.98124\n",
            "epoch: 5, passed number of graphs: 768, train running loss: 0.00680 (passed time: 28m 31s)\n",
            "          acc: 0.98919, fpr: 0.01079, fnr: 0.01164, rec: 0.98836, prc: 0.66506, f1: 0.79510, f1_macro: 0.89478\n",
            "Validation --- epoch: 5, loss: 0.04150\n",
            "          prc: 0.66198, fnr: 0.03062, acc: 0.98673, f1_macro: 0.88331, rec: 0.96938, fpr: 0.01288, f1: 0.77346\n",
            "epoch: 6, passed number of graphs: 96, train running loss: 0.01021 (passed time: 30m 31s)\n",
            "          acc: 0.99853, fpr: 0.00143, fnr: 0.00313, rec: 0.99687, prc: 0.93893, f1: 0.96703, f1_macro: 0.98314\n",
            "epoch: 6, passed number of graphs: 192, train running loss: 0.01085 (passed time: 31m 32s)\n",
            "          acc: 0.99603, fpr: 0.00187, fnr: 0.10046, rec: 0.89954, prc: 0.91275, f1: 0.90610, f1_macro: 0.95203\n",
            "epoch: 6, passed number of graphs: 288, train running loss: 0.00982 (passed time: 32m 32s)\n",
            "          acc: 0.99466, fpr: 0.00544, fnr: 0.00082, rec: 0.99918, prc: 0.80067, f1: 0.88898, f1_macro: 0.94312\n",
            "epoch: 6, passed number of graphs: 384, train running loss: 0.00832 (passed time: 33m 32s)\n",
            "          acc: 0.99924, fpr: 0.00075, fnr: 0.00121, rec: 0.99879, prc: 0.96700, f1: 0.98263, f1_macro: 0.99112\n",
            "epoch: 6, passed number of graphs: 480, train running loss: 0.00726 (passed time: 34m 32s)\n",
            "          acc: 0.99953, fpr: 0.00046, fnr: 0.00057, rec: 0.99943, prc: 0.97942, f1: 0.98932, f1_macro: 0.99454\n",
            "epoch: 6, passed number of graphs: 576, train running loss: 0.00731 (passed time: 35m 32s)\n",
            "          acc: 0.99796, fpr: 0.00207, fnr: 0.00088, rec: 0.99912, prc: 0.91446, f1: 0.95491, f1_macro: 0.97693\n",
            "epoch: 6, passed number of graphs: 672, train running loss: 0.00736 (passed time: 36m 32s)\n",
            "          acc: 0.99746, fpr: 0.00115, fnr: 0.06563, rec: 0.93437, prc: 0.94675, f1: 0.94052, f1_macro: 0.96961\n",
            "epoch: 6, passed number of graphs: 768, train running loss: 0.00708 (passed time: 37m 32s)\n",
            "          acc: 0.99958, fpr: 0.00040, fnr: 0.00114, rec: 0.99886, prc: 0.98176, f1: 0.99023, f1_macro: 0.99501\n",
            "Validation --- epoch: 6, loss: 0.00807\n",
            "          prc: 0.97792, fnr: 0.01415, acc: 0.99919, f1_macro: 0.99011, rec: 0.98585, fpr: 0.00052, f1: 0.98064\n",
            "Better model saved at ./saved_models/temp.pt.\n",
            "epoch: 7, passed number of graphs: 96, train running loss: 0.00483 (passed time: 39m 33s)\n",
            "          acc: 0.99993, fpr: 0.00005, fnr: 0.00104, rec: 0.99896, prc: 0.99767, f1: 0.99831, f1_macro: 0.99914\n",
            "epoch: 7, passed number of graphs: 192, train running loss: 0.00575 (passed time: 40m 33s)\n",
            "          acc: 0.99705, fpr: 0.00085, fnr: 0.09973, rec: 0.90027, prc: 0.95860, f1: 0.92852, f1_macro: 0.96351\n",
            "epoch: 7, passed number of graphs: 288, train running loss: 0.00493 (passed time: 41m 33s)\n",
            "          acc: 0.99783, fpr: 0.00222, fnr: 0.00000, rec: 1.00000, prc: 0.90794, f1: 0.95175, f1_macro: 0.97532\n",
            "epoch: 7, passed number of graphs: 384, train running loss: 0.00421 (passed time: 42m 34s)\n",
            "          acc: 0.99963, fpr: 0.00038, fnr: 0.00008, rec: 0.99992, prc: 0.98324, f1: 0.99151, f1_macro: 0.99566\n",
            "epoch: 7, passed number of graphs: 480, train running loss: 0.00377 (passed time: 43m 33s)\n",
            "          acc: 0.99956, fpr: 0.00045, fnr: 0.00008, rec: 0.99992, prc: 0.98014, f1: 0.98993, f1_macro: 0.99485\n",
            "epoch: 7, passed number of graphs: 576, train running loss: 0.00477 (passed time: 44m 34s)\n",
            "          acc: 0.98384, fpr: 0.01529, fnr: 0.05548, rec: 0.94452, prc: 0.57727, f1: 0.71658, f1_macro: 0.85413\n",
            "epoch: 7, passed number of graphs: 672, train running loss: 0.00707 (passed time: 45m 34s)\n",
            "          acc: 0.99249, fpr: 0.00625, fnr: 0.06499, rec: 0.93501, prc: 0.76644, f1: 0.84238, f1_macro: 0.91926\n",
            "epoch: 7, passed number of graphs: 768, train running loss: 0.00729 (passed time: 46m 34s)\n",
            "          acc: 0.99729, fpr: 0.00258, fnr: 0.00863, rec: 0.99137, prc: 0.89287, f1: 0.93955, f1_macro: 0.96908\n",
            "Validation --- epoch: 7, loss: 0.01428\n",
            "          prc: 0.91464, fnr: 0.02120, acc: 0.99722, f1_macro: 0.97013, rec: 0.97880, fpr: 0.00238, f1: 0.94169\n",
            "epoch: 8, passed number of graphs: 96, train running loss: 0.00793 (passed time: 48m 35s)\n",
            "          acc: 0.99823, fpr: 0.00177, fnr: 0.00153, rec: 0.99847, prc: 0.92539, f1: 0.96054, f1_macro: 0.97982\n",
            "epoch: 8, passed number of graphs: 192, train running loss: 0.00889 (passed time: 49m 35s)\n",
            "          acc: 0.99565, fpr: 0.00225, fnr: 0.10103, rec: 0.89897, prc: 0.89700, f1: 0.89798, f1_macro: 0.94788\n",
            "epoch: 8, passed number of graphs: 288, train running loss: 0.00820 (passed time: 50m 35s)\n",
            "          acc: 0.99760, fpr: 0.00239, fnr: 0.00302, rec: 0.99698, prc: 0.90133, f1: 0.94675, f1_macro: 0.97276\n",
            "epoch: 8, passed number of graphs: 384, train running loss: 0.00685 (passed time: 51m 35s)\n",
            "          acc: 0.99828, fpr: 0.00172, fnr: 0.00170, rec: 0.99830, prc: 0.92757, f1: 0.96164, f1_macro: 0.98038\n",
            "epoch: 8, passed number of graphs: 480, train running loss: 0.00600 (passed time: 52m 35s)\n",
            "          acc: 0.99973, fpr: 0.00026, fnr: 0.00057, rec: 0.99943, prc: 0.98832, f1: 0.99384, f1_macro: 0.99685\n",
            "epoch: 8, passed number of graphs: 576, train running loss: 0.00591 (passed time: 53m 36s)\n",
            "          acc: 0.99767, fpr: 0.00238, fnr: 0.00008, rec: 0.99992, prc: 0.90278, f1: 0.94887, f1_macro: 0.97384\n",
            "epoch: 8, passed number of graphs: 672, train running loss: 0.00599 (passed time: 54m 36s)\n",
            "          acc: 0.99756, fpr: 0.00112, fnr: 0.06283, rec: 0.93717, prc: 0.94844, f1: 0.94277, f1_macro: 0.97076\n",
            "epoch: 8, passed number of graphs: 768, train running loss: 0.00581 (passed time: 55m 36s)\n",
            "          acc: 0.99880, fpr: 0.00119, fnr: 0.00155, rec: 0.99845, prc: 0.94769, f1: 0.97241, f1_macro: 0.98590\n",
            "Validation --- epoch: 8, loss: 0.73633\n",
            "          prc: 0.17053, fnr: 0.00596, acc: 0.89005, f1_macro: 0.61478, rec: 0.99404, fpr: 0.11224, f1: 0.28931\n",
            "epoch: 9, passed number of graphs: 96, train running loss: 0.00266 (passed time: 57m 36s)\n",
            "          acc: 0.99995, fpr: 0.00004, fnr: 0.00048, rec: 0.99952, prc: 0.99815, f1: 0.99884, f1_macro: 0.99941\n",
            "epoch: 9, passed number of graphs: 192, train running loss: 0.00316 (passed time: 58m 37s)\n",
            "          acc: 0.99660, fpr: 0.00148, fnr: 0.09184, rec: 0.90816, prc: 0.93049, f1: 0.91919, f1_macro: 0.95873\n",
            "epoch: 9, passed number of graphs: 288, train running loss: 0.00252 (passed time: 59m 37s)\n",
            "          acc: 0.99865, fpr: 0.00138, fnr: 0.00008, rec: 0.99992, prc: 0.94073, f1: 0.96942, f1_macro: 0.98436\n",
            "epoch: 9, passed number of graphs: 384, train running loss: 0.00225 (passed time: 1h 0m 37s)\n",
            "          acc: 0.99992, fpr: 0.00007, fnr: 0.00024, rec: 0.99976, prc: 0.99670, f1: 0.99823, f1_macro: 0.99909\n",
            "epoch: 9, passed number of graphs: 480, train running loss: 0.00204 (passed time: 1h 1m 37s)\n",
            "          acc: 0.99975, fpr: 0.00025, fnr: 0.00016, rec: 0.99984, prc: 0.98873, f1: 0.99425, f1_macro: 0.99706\n",
            "epoch: 9, passed number of graphs: 576, train running loss: 0.00191 (passed time: 1h 2m 37s)\n",
            "          acc: 0.99909, fpr: 0.00092, fnr: 0.00008, rec: 0.99992, prc: 0.95984, f1: 0.97947, f1_macro: 0.98950\n",
            "epoch: 9, passed number of graphs: 672, train running loss: 0.00188 (passed time: 1h 3m 37s)\n",
            "          acc: 0.99932, fpr: 0.00066, fnr: 0.00168, rec: 0.99832, prc: 0.97089, f1: 0.98441, f1_macro: 0.99203\n",
            "epoch: 9, passed number of graphs: 768, train running loss: 0.00178 (passed time: 1h 4m 38s)\n",
            "          acc: 0.99908, fpr: 0.00093, fnr: 0.00033, rec: 0.99967, prc: 0.95870, f1: 0.97876, f1_macro: 0.98914\n",
            "Validation --- epoch: 9, loss: 0.05867\n",
            "          prc: 0.61373, fnr: 0.00688, acc: 0.98197, f1_macro: 0.86517, rec: 0.99312, fpr: 0.01827, f1: 0.73970\n",
            "epoch: 10, passed number of graphs: 96, train running loss: 0.00075 (passed time: 1h 6m 38s)\n",
            "          acc: 0.99995, fpr: 0.00005, fnr: 0.00024, rec: 0.99976, prc: 0.99783, f1: 0.99880, f1_macro: 0.99938\n",
            "epoch: 10, passed number of graphs: 192, train running loss: 0.00142 (passed time: 1h 7m 38s)\n",
            "          acc: 0.99763, fpr: 0.00029, fnr: 0.09810, rec: 0.90190, prc: 0.98560, f1: 0.94189, f1_macro: 0.97034\n",
            "epoch: 10, passed number of graphs: 288, train running loss: 0.00126 (passed time: 1h 8m 38s)\n",
            "          acc: 0.99881, fpr: 0.00122, fnr: 0.00016, rec: 0.99984, prc: 0.94726, f1: 0.97284, f1_macro: 0.98611\n",
            "epoch: 10, passed number of graphs: 384, train running loss: 0.00125 (passed time: 1h 9m 39s)\n",
            "          acc: 0.99993, fpr: 0.00006, fnr: 0.00016, rec: 0.99984, prc: 0.99710, f1: 0.99847, f1_macro: 0.99922\n",
            "epoch: 10, passed number of graphs: 480, train running loss: 0.00111 (passed time: 1h 10m 39s)\n",
            "          acc: 0.99976, fpr: 0.00024, fnr: 0.00025, rec: 0.99975, prc: 0.98905, f1: 0.99437, f1_macro: 0.99712\n",
            "epoch: 10, passed number of graphs: 576, train running loss: 0.00103 (passed time: 1h 11m 39s)\n",
            "          acc: 0.99975, fpr: 0.00026, fnr: 0.00000, rec: 1.00000, prc: 0.98841, f1: 0.99417, f1_macro: 0.99702\n",
            "epoch: 10, passed number of graphs: 672, train running loss: 0.00099 (passed time: 1h 12m 39s)\n",
            "          acc: 0.99950, fpr: 0.00051, fnr: 0.00040, rec: 0.99960, prc: 0.97740, f1: 0.98838, f1_macro: 0.99406\n",
            "epoch: 10, passed number of graphs: 768, train running loss: 0.00094 (passed time: 1h 13m 39s)\n",
            "          acc: 0.99991, fpr: 0.00008, fnr: 0.00024, rec: 0.99976, prc: 0.99619, f1: 0.99797, f1_macro: 0.99896\n",
            "Validation --- epoch: 10, loss: 0.00223\n",
            "          prc: 0.99194, fnr: 0.00800, acc: 0.99959, f1_macro: 0.99523, rec: 0.99200, fpr: 0.00025, f1: 0.99066\n",
            "Better model saved at ./saved_models/temp.pt.\n",
            "epoch: 11, passed number of graphs: 96, train running loss: 0.00040 (passed time: 1h 15m 40s)\n",
            "          acc: 0.99996, fpr: 0.00003, fnr: 0.00024, rec: 0.99976, prc: 0.99848, f1: 0.99912, f1_macro: 0.99955\n",
            "epoch: 11, passed number of graphs: 192, train running loss: 0.00045 (passed time: 1h 16m 40s)\n",
            "          acc: 0.99827, fpr: 0.00176, fnr: 0.00033, rec: 0.99967, prc: 0.92503, f1: 0.96090, f1_macro: 0.98001\n",
            "epoch: 11, passed number of graphs: 288, train running loss: 0.00042 (passed time: 1h 17m 40s)\n",
            "          acc: 0.99982, fpr: 0.00019, fnr: 0.00008, rec: 0.99992, prc: 0.99159, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 11, passed number of graphs: 384, train running loss: 0.00053 (passed time: 1h 18m 40s)\n",
            "          acc: 0.99993, fpr: 0.00006, fnr: 0.00024, rec: 0.99976, prc: 0.99718, f1: 0.99847, f1_macro: 0.99922\n",
            "epoch: 11, passed number of graphs: 480, train running loss: 0.00052 (passed time: 1h 19m 40s)\n",
            "          acc: 0.99970, fpr: 0.00030, fnr: 0.00016, rec: 0.99984, prc: 0.98665, f1: 0.99320, f1_macro: 0.99652\n",
            "epoch: 11, passed number of graphs: 576, train running loss: 0.00070 (passed time: 1h 20m 41s)\n",
            "          acc: 0.99707, fpr: 0.00300, fnr: 0.00008, rec: 0.99992, prc: 0.88063, f1: 0.93649, f1_macro: 0.96750\n",
            "epoch: 11, passed number of graphs: 672, train running loss: 0.00076 (passed time: 1h 21m 41s)\n",
            "          acc: 0.99957, fpr: 0.00043, fnr: 0.00064, rec: 0.99936, prc: 0.98094, f1: 0.99006, f1_macro: 0.99492\n",
            "epoch: 11, passed number of graphs: 768, train running loss: 0.00095 (passed time: 1h 22m 41s)\n",
            "          acc: 0.97360, fpr: 0.02697, fnr: 0.00016, rec: 0.99984, prc: 0.44553, f1: 0.61639, f1_macro: 0.80136\n",
            "Validation --- epoch: 11, loss: 0.09179\n",
            "          prc: 0.55661, fnr: 0.01007, acc: 0.98169, f1_macro: 0.84902, rec: 0.98993, fpr: 0.01849, f1: 0.70750\n",
            "epoch: 12, passed number of graphs: 96, train running loss: 0.00715 (passed time: 1h 24m 41s)\n",
            "          acc: 0.99957, fpr: 0.00040, fnr: 0.00161, rec: 0.99839, prc: 0.98214, f1: 0.99020, f1_macro: 0.99499\n",
            "epoch: 12, passed number of graphs: 192, train running loss: 0.00771 (passed time: 1h 25m 42s)\n",
            "          acc: 0.99671, fpr: 0.00121, fnr: 0.09900, rec: 0.90100, prc: 0.94208, f1: 0.92108, f1_macro: 0.95970\n",
            "epoch: 12, passed number of graphs: 288, train running loss: 0.00664 (passed time: 1h 26m 42s)\n",
            "          acc: 0.99913, fpr: 0.00088, fnr: 0.00049, rec: 0.99951, prc: 0.96135, f1: 0.98006, f1_macro: 0.98981\n",
            "epoch: 12, passed number of graphs: 384, train running loss: 0.00547 (passed time: 1h 27m 42s)\n",
            "          acc: 0.99974, fpr: 0.00026, fnr: 0.00032, rec: 0.99968, prc: 0.98850, f1: 0.99406, f1_macro: 0.99696\n",
            "epoch: 12, passed number of graphs: 480, train running loss: 0.00488 (passed time: 1h 28m 42s)\n",
            "          acc: 0.99974, fpr: 0.00026, fnr: 0.00041, rec: 0.99959, prc: 0.98840, f1: 0.99396, f1_macro: 0.99692\n",
            "epoch: 12, passed number of graphs: 576, train running loss: 0.00436 (passed time: 1h 29m 42s)\n",
            "          acc: 0.99959, fpr: 0.00042, fnr: 0.00000, rec: 1.00000, prc: 0.98125, f1: 0.99054, f1_macro: 0.99516\n",
            "epoch: 12, passed number of graphs: 672, train running loss: 0.00440 (passed time: 1h 30m 42s)\n",
            "          acc: 0.99870, fpr: 0.00005, fnr: 0.05833, rec: 0.94167, prc: 0.99745, f1: 0.96876, f1_macro: 0.98405\n",
            "epoch: 12, passed number of graphs: 768, train running loss: 0.00430 (passed time: 1h 31m 42s)\n",
            "          acc: 0.99967, fpr: 0.00032, fnr: 0.00049, rec: 0.99951, prc: 0.98523, f1: 0.99232, f1_macro: 0.99608\n",
            "Validation --- epoch: 12, loss: 0.00429\n",
            "          prc: 0.99509, fnr: 0.01390, acc: 0.99960, f1_macro: 0.99466, rec: 0.98610, fpr: 0.00010, f1: 0.98951\n",
            "epoch: 13, passed number of graphs: 96, train running loss: 0.00297 (passed time: 1h 33m 43s)\n",
            "          acc: 0.99974, fpr: 0.00025, fnr: 0.00032, rec: 0.99968, prc: 0.98856, f1: 0.99409, f1_macro: 0.99698\n",
            "epoch: 13, passed number of graphs: 192, train running loss: 0.00307 (passed time: 1h 34m 43s)\n",
            "          acc: 0.99659, fpr: 0.00138, fnr: 0.09680, rec: 0.90320, prc: 0.93444, f1: 0.91855, f1_macro: 0.95840\n",
            "epoch: 13, passed number of graphs: 288, train running loss: 0.00256 (passed time: 1h 35m 43s)\n",
            "          acc: 0.99966, fpr: 0.00034, fnr: 0.00041, rec: 0.99959, prc: 0.98490, f1: 0.99219, f1_macro: 0.99601\n",
            "epoch: 13, passed number of graphs: 384, train running loss: 0.00230 (passed time: 1h 36m 43s)\n",
            "          acc: 0.99988, fpr: 0.00012, fnr: 0.00016, rec: 0.99984, prc: 0.99462, f1: 0.99722, f1_macro: 0.99858\n",
            "epoch: 13, passed number of graphs: 480, train running loss: 0.00225 (passed time: 1h 37m 43s)\n",
            "          acc: 0.99974, fpr: 0.00025, fnr: 0.00049, rec: 0.99951, prc: 0.98872, f1: 0.99409, f1_macro: 0.99698\n",
            "epoch: 13, passed number of graphs: 576, train running loss: 0.00200 (passed time: 1h 38m 44s)\n",
            "          acc: 0.99966, fpr: 0.00035, fnr: 0.00016, rec: 0.99984, prc: 0.98458, f1: 0.99215, f1_macro: 0.99599\n",
            "epoch: 13, passed number of graphs: 672, train running loss: 0.00202 (passed time: 1h 39m 44s)\n",
            "          acc: 0.99901, fpr: 0.00099, fnr: 0.00096, rec: 0.99904, prc: 0.95696, f1: 0.97755, f1_macro: 0.98852\n",
            "epoch: 13, passed number of graphs: 768, train running loss: 0.00212 (passed time: 1h 40m 44s)\n",
            "          acc: 0.99994, fpr: 0.00005, fnr: 0.00081, rec: 0.99919, prc: 0.99780, f1: 0.99849, f1_macro: 0.99923\n",
            "Validation --- epoch: 13, loss: 0.00291\n",
            "          prc: 0.99628, fnr: 0.01065, acc: 0.99969, f1_macro: 0.99582, rec: 0.98935, fpr: 0.00008, f1: 0.99180\n",
            "epoch: 14, passed number of graphs: 96, train running loss: 0.00156 (passed time: 1h 42m 44s)\n",
            "          acc: 0.99982, fpr: 0.00017, fnr: 0.00056, rec: 0.99944, prc: 0.99218, f1: 0.99580, f1_macro: 0.99785\n",
            "epoch: 14, passed number of graphs: 192, train running loss: 0.00156 (passed time: 1h 43m 45s)\n",
            "          acc: 0.99912, fpr: 0.00081, fnr: 0.00431, rec: 0.99569, prc: 0.96401, f1: 0.97959, f1_macro: 0.98957\n",
            "epoch: 14, passed number of graphs: 288, train running loss: 0.00130 (passed time: 1h 44m 45s)\n",
            "          acc: 0.99973, fpr: 0.00027, fnr: 0.00016, rec: 0.99984, prc: 0.98768, f1: 0.99372, f1_macro: 0.99679\n",
            "epoch: 14, passed number of graphs: 384, train running loss: 0.00129 (passed time: 1h 45m 45s)\n",
            "          acc: 0.99990, fpr: 0.00010, fnr: 0.00016, rec: 0.99984, prc: 0.99534, f1: 0.99758, f1_macro: 0.99876\n",
            "epoch: 14, passed number of graphs: 480, train running loss: 0.00138 (passed time: 1h 46m 45s)\n",
            "          acc: 0.99968, fpr: 0.00032, fnr: 0.00033, rec: 0.99967, prc: 0.98553, f1: 0.99255, f1_macro: 0.99619\n",
            "epoch: 14, passed number of graphs: 576, train running loss: 0.00125 (passed time: 1h 47m 45s)\n",
            "          acc: 0.99969, fpr: 0.00031, fnr: 0.00024, rec: 0.99976, prc: 0.98630, f1: 0.99298, f1_macro: 0.99641\n",
            "epoch: 14, passed number of graphs: 672, train running loss: 0.00123 (passed time: 1h 48m 45s)\n",
            "          acc: 0.99960, fpr: 0.00039, fnr: 0.00104, rec: 0.99896, prc: 0.98271, f1: 0.99077, f1_macro: 0.99528\n",
            "epoch: 14, passed number of graphs: 768, train running loss: 0.00139 (passed time: 1h 49m 46s)\n",
            "          acc: 0.99992, fpr: 0.00007, fnr: 0.00049, rec: 0.99951, prc: 0.99667, f1: 0.99809, f1_macro: 0.99902\n",
            "Validation --- epoch: 14, loss: 0.00311\n",
            "          prc: 0.98720, fnr: 0.00717, acc: 0.99956, f1_macro: 0.99447, rec: 0.99283, fpr: 0.00029, f1: 0.98916\n",
            "epoch: 15, passed number of graphs: 96, train running loss: 0.00082 (passed time: 1h 51m 46s)\n",
            "          acc: 0.99976, fpr: 0.00025, fnr: 0.00016, rec: 0.99984, prc: 0.98895, f1: 0.99437, f1_macro: 0.99712\n",
            "epoch: 15, passed number of graphs: 192, train running loss: 0.00076 (passed time: 1h 52m 46s)\n",
            "          acc: 0.99954, fpr: 0.00041, fnr: 0.00277, rec: 0.99723, prc: 0.98143, f1: 0.98927, f1_macro: 0.99452\n",
            "epoch: 15, passed number of graphs: 288, train running loss: 0.00070 (passed time: 1h 53m 46s)\n",
            "          acc: 0.99982, fpr: 0.00018, fnr: 0.00008, rec: 0.99992, prc: 0.99191, f1: 0.99590, f1_macro: 0.99791\n",
            "epoch: 15, passed number of graphs: 384, train running loss: 0.00077 (passed time: 1h 54m 47s)\n",
            "          acc: 0.99990, fpr: 0.00010, fnr: 0.00016, rec: 0.99984, prc: 0.99566, f1: 0.99774, f1_macro: 0.99885\n",
            "epoch: 15, passed number of graphs: 480, train running loss: 0.00086 (passed time: 1h 55m 47s)\n",
            "          acc: 0.99956, fpr: 0.00044, fnr: 0.00041, rec: 0.99959, prc: 0.98061, f1: 0.99001, f1_macro: 0.99489\n",
            "epoch: 15, passed number of graphs: 576, train running loss: 0.00080 (passed time: 1h 56m 47s)\n",
            "          acc: 0.99968, fpr: 0.00032, fnr: 0.00024, rec: 0.99976, prc: 0.98583, f1: 0.99274, f1_macro: 0.99629\n",
            "epoch: 15, passed number of graphs: 672, train running loss: 0.00080 (passed time: 1h 57m 47s)\n",
            "          acc: 0.99979, fpr: 0.00020, fnr: 0.00080, rec: 0.99920, prc: 0.99109, f1: 0.99513, f1_macro: 0.99751\n",
            "epoch: 15, passed number of graphs: 768, train running loss: 0.00098 (passed time: 1h 58m 47s)\n",
            "          acc: 0.99992, fpr: 0.00007, fnr: 0.00041, rec: 0.99959, prc: 0.99675, f1: 0.99817, f1_macro: 0.99907\n",
            "Validation --- epoch: 15, loss: 0.01138\n",
            "          prc: 0.90636, fnr: 0.00588, acc: 0.99717, f1_macro: 0.97087, rec: 0.99412, fpr: 0.00276, f1: 0.94319\n",
            "epoch: 16, passed number of graphs: 96, train running loss: 0.00068 (passed time: 2h 0m 48s)\n",
            "          acc: 0.99982, fpr: 0.00018, fnr: 0.00016, rec: 0.99984, prc: 0.99179, f1: 0.99580, f1_macro: 0.99785\n",
            "epoch: 16, passed number of graphs: 192, train running loss: 0.00064 (passed time: 2h 1m 48s)\n",
            "          acc: 0.99955, fpr: 0.00042, fnr: 0.00195, rec: 0.99805, prc: 0.98121, f1: 0.98956, f1_macro: 0.99466\n",
            "epoch: 16, passed number of graphs: 288, train running loss: 0.00061 (passed time: 2h 2m 48s)\n",
            "          acc: 0.99982, fpr: 0.00018, fnr: 0.00016, rec: 0.99984, prc: 0.99199, f1: 0.99590, f1_macro: 0.99791\n",
            "epoch: 16, passed number of graphs: 384, train running loss: 0.00069 (passed time: 2h 3m 48s)\n",
            "          acc: 0.99991, fpr: 0.00009, fnr: 0.00016, rec: 0.99984, prc: 0.99606, f1: 0.99794, f1_macro: 0.99895\n",
            "epoch: 16, passed number of graphs: 480, train running loss: 0.00082 (passed time: 2h 4m 48s)\n",
            "          acc: 0.99962, fpr: 0.00038, fnr: 0.00049, rec: 0.99951, prc: 0.98298, f1: 0.99117, f1_macro: 0.99549\n",
            "epoch: 16, passed number of graphs: 576, train running loss: 0.00079 (passed time: 2h 5m 48s)\n",
            "          acc: 0.99971, fpr: 0.00030, fnr: 0.00016, rec: 0.99984, prc: 0.98677, f1: 0.99326, f1_macro: 0.99655\n",
            "epoch: 16, passed number of graphs: 672, train running loss: 0.00081 (passed time: 2h 6m 48s)\n",
            "          acc: 0.99978, fpr: 0.00019, fnr: 0.00177, rec: 0.99823, prc: 0.99155, f1: 0.99488, f1_macro: 0.99738\n",
            "epoch: 16, passed number of graphs: 768, train running loss: 0.00099 (passed time: 2h 7m 49s)\n",
            "          acc: 0.99992, fpr: 0.00008, fnr: 0.00041, rec: 0.99959, prc: 0.99651, f1: 0.99805, f1_macro: 0.99900\n",
            "Validation --- epoch: 16, loss: 0.00767\n",
            "          prc: 0.93682, fnr: 0.00641, acc: 0.99821, f1_macro: 0.98039, rec: 0.99359, fpr: 0.00169, f1: 0.96169\n",
            "epoch: 17, passed number of graphs: 96, train running loss: 0.00079 (passed time: 2h 9m 49s)\n",
            "          acc: 0.99993, fpr: 0.00007, fnr: 0.00000, rec: 1.00000, prc: 0.99664, f1: 0.99832, f1_macro: 0.99914\n",
            "epoch: 17, passed number of graphs: 192, train running loss: 0.00071 (passed time: 2h 10m 49s)\n",
            "          acc: 0.99954, fpr: 0.00042, fnr: 0.00236, rec: 0.99764, prc: 0.98096, f1: 0.98923, f1_macro: 0.99450\n",
            "epoch: 17, passed number of graphs: 288, train running loss: 0.00068 (passed time: 2h 11m 49s)\n",
            "          acc: 0.99983, fpr: 0.00018, fnr: 0.00008, rec: 0.99992, prc: 0.99199, f1: 0.99594, f1_macro: 0.99793\n",
            "epoch: 17, passed number of graphs: 384, train running loss: 0.00077 (passed time: 2h 12m 49s)\n",
            "          acc: 0.99991, fpr: 0.00008, fnr: 0.00032, rec: 0.99968, prc: 0.99638, f1: 0.99802, f1_macro: 0.99899\n",
            "epoch: 17, passed number of graphs: 480, train running loss: 0.00079 (passed time: 2h 13m 49s)\n",
            "          acc: 0.99955, fpr: 0.00045, fnr: 0.00033, rec: 0.99967, prc: 0.97982, f1: 0.98965, f1_macro: 0.99471\n",
            "epoch: 17, passed number of graphs: 576, train running loss: 0.00073 (passed time: 2h 14m 50s)\n",
            "          acc: 0.99971, fpr: 0.00029, fnr: 0.00016, rec: 0.99984, prc: 0.98684, f1: 0.99330, f1_macro: 0.99658\n",
            "epoch: 17, passed number of graphs: 672, train running loss: 0.00074 (passed time: 2h 15m 50s)\n",
            "          acc: 0.99979, fpr: 0.00018, fnr: 0.00144, rec: 0.99856, prc: 0.99163, f1: 0.99508, f1_macro: 0.99749\n",
            "epoch: 17, passed number of graphs: 768, train running loss: 0.00091 (passed time: 2h 16m 50s)\n",
            "          acc: 0.99992, fpr: 0.00007, fnr: 0.00041, rec: 0.99959, prc: 0.99683, f1: 0.99821, f1_macro: 0.99909\n",
            "Validation --- epoch: 17, loss: 0.00317\n",
            "          prc: 0.98566, fnr: 0.00706, acc: 0.99952, f1_macro: 0.99407, rec: 0.99294, fpr: 0.00034, f1: 0.98838\n",
            "epoch: 18, passed number of graphs: 96, train running loss: 0.00075 (passed time: 2h 18m 50s)\n",
            "          acc: 0.99994, fpr: 0.00006, fnr: 0.00000, rec: 1.00000, prc: 0.99728, f1: 0.99864, f1_macro: 0.99930\n",
            "epoch: 18, passed number of graphs: 192, train running loss: 0.00067 (passed time: 2h 19m 51s)\n",
            "          acc: 0.99955, fpr: 0.00042, fnr: 0.00163, rec: 0.99837, prc: 0.98082, f1: 0.98952, f1_macro: 0.99464\n",
            "epoch: 18, passed number of graphs: 288, train running loss: 0.00064 (passed time: 2h 20m 51s)\n",
            "          acc: 0.99983, fpr: 0.00018, fnr: 0.00008, rec: 0.99992, prc: 0.99199, f1: 0.99594, f1_macro: 0.99793\n",
            "epoch: 18, passed number of graphs: 384, train running loss: 0.00074 (passed time: 2h 21m 51s)\n",
            "          acc: 0.99992, fpr: 0.00007, fnr: 0.00032, rec: 0.99968, prc: 0.99670, f1: 0.99819, f1_macro: 0.99907\n",
            "epoch: 18, passed number of graphs: 480, train running loss: 0.00076 (passed time: 2h 22m 51s)\n",
            "          acc: 0.99956, fpr: 0.00045, fnr: 0.00016, rec: 0.99984, prc: 0.98014, f1: 0.98989, f1_macro: 0.99483\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b64b037c8de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# ========== train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-b64b037c8de9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_dataset, test_dataset, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mnum_train_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-506f0a28c2e8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# only open once in each process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mgraph_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5group_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-506f0a28c2e8>\u001b[0m in \u001b[0;36mh5group_to_dict\u001b[0;34m(h5group)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Data utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mh5group_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgroup_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-506f0a28c2e8>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Data utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mh5group_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgroup_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============== some default parameters =============\n",
        "devid = 0\n",
        "seed = 0\n",
        "logmode = 'w'\n",
        "log_interval = 96\n",
        "\n",
        "dim_input_feature = 1\n",
        "dim_hidden_feature = 32\n",
        "\n",
        "num_layers = 12\n",
        "num_classes = 2 \n",
        "\n",
        "dropout = 0.0\n",
        "bias = True\n",
        "\n",
        "lr = 0.005 # learning rate\n",
        "weight_decay = 5e-4\n",
        "epochs = 50\n",
        "save_dir = './saved_models'\n",
        "save_name = 'temp.pt'\n",
        "# ====================================================\n",
        "\n",
        "def train(model, train_loader, val_dataset, test_dataset, optimizer, scheduler=None):\n",
        "    device = next(model.parameters()).device\n",
        "    predictor = PygModelPredictor(model)\n",
        "\n",
        "    best_epoch = 0\n",
        "    min_avg_lost = np.inf\n",
        "    start = time.time()\n",
        "    for ep in range(epochs):\n",
        "        loss_avg_train = 0\n",
        "        num_train_graph = 0\n",
        "        model.train()\n",
        "        for n, batch in enumerate(train_loader):\n",
        "            batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = model(batch.x, batch.edge_index)\n",
        "            loss = criterion(x, batch.y.long())\n",
        "\n",
        "            loss_avg_train += float(loss)\n",
        "            num_train_graph += batch.num_graphs\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if num_train_graph % log_interval == 0 or n == len(train_loader) - 1:\n",
        "                with torch.no_grad():\n",
        "                    # pred = x.argmax(dim=1)\n",
        "                    pred_prob = torch.softmax(x, dim=1)[:, 1]\n",
        "                    y = batch.y.long()\n",
        "                    result_dict = eval_metrics(y, pred_prob)\n",
        "                print(f'epoch: {ep + 1}, passed number of graphs: {num_train_graph}, '\n",
        "                        f'train running loss: {loss_avg_train / num_train_graph:.5f} (passed time: {time_since(start)})')\n",
        "                print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict.items()]))\n",
        "\n",
        "        result_dict_avg, loss_avg = eval_predictor(val_dataset, predictor)\n",
        "        print(f'Validation --- epoch: {ep + 1}, loss: {loss_avg:.5f}')\n",
        "        print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(loss_avg)\n",
        "\n",
        "        if loss_avg < min_avg_lost:\n",
        "            torch.save(model, os.path.join(save_dir, save_name))\n",
        "            print(f'Better model saved at {os.path.join(save_dir, save_name)}.')\n",
        "            best_epoch = ep\n",
        "            min_avg_lost = loss_avg\n",
        "            # Tai model ve de essemble learning\n",
        "\n",
        "    best_model = torch.load(os.path.join(save_dir, save_name))\n",
        "    print('*' * 12 + f' best model obtained after epoch {best_epoch + 1}, '\n",
        "                       f'saved at {os.path.join(save_dir, save_name)} ' + '*' * 12)\n",
        "    \n",
        "    predictor = PygModelPredictor(best_model)\n",
        "\n",
        "    result_dict_avg, loss_avg = eval_predictor(test_dataset, predictor)\n",
        "    print(f'Testing --- loss: {loss_avg:.5f}')\n",
        "    print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # ========== random seeds and device\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(f'cuda:{devid}') if devid > -1 else torch.device('cpu')\n",
        "\n",
        "    # ========== logging setup\n",
        "    log_name = os.path.splitext(save_name)[0]\n",
        "    # logger = logging_config(__name__, folder=save_dir, name=log_name, filemode=logmode)\n",
        "    # logger = logging_config(os.path.basename(__file__), folder=save_dir, name=log_name, filemode=logmode)\n",
        "\n",
        "    print('python ' + ' '.join(sys.argv))\n",
        "    print('-' * 30)\n",
        "    #logger.info(args)\n",
        "    print('-' * 30)\n",
        "    print(time.ctime())\n",
        "    print('-' * 30)\n",
        "\n",
        "    # ========== define the model, optimizer, and loss\n",
        "\n",
        "    model = GINModel(dim_input_feature,\n",
        "                     dim_hidden_feature,\n",
        "                     num_layers,\n",
        "                     num_classes,\n",
        "                     dropout=dropout)\n",
        "\n",
        "    print('model ' + '-' * 10)\n",
        "    print(repr(model))\n",
        "    model.to(device)\n",
        "\n",
        "    class_weight = torch.Tensor([0.05, 0.95])\n",
        "    class_weight = class_weight.cuda(device=0)\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=class_weight)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=1)\n",
        "\n",
        "    # ========== train the model\n",
        "    train(model, train_loader, val_ds, test_ds, optimizer, scheduler)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4KD-KUsKDiLE",
        "r0VJxZnIDpJT",
        "igYJ4y99D-bU",
        "z_dcpDhREijU",
        "fTEnWpOOEZW9",
        "8rh6Ca1XE6ar",
        "RRCYp7yuLxMe"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}